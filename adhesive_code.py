# -*- coding: utf-8 -*-
"""Adhesive_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lo7NNDOR89VDrMhvpyUtuSq_pdAhCqJI

# Predicting Tensile Capacity
Adhesive Anchors \\

Coded by Erick Melgarejo and Luis Bedriñana

Nov., 2023

Reference: Bedriñana et al. 2024 WCEE_v4


Change Log:

-
"""
# Commented out IPython magic to ensure Python compatibility.
 #Imports
import xgboost as xgb
import shap
import numpy as np
import matplotlib as mpl
import os
import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import QuantileTransformer
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
import time
from sklearn.metrics import make_scorer
from sklearn.model_selection import cross_validate
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from matplotlib.colors import Normalize
from scipy.stats import norm
from scipy import interpolate
from statsmodels.formula.api import ols
# %matplotlib inline


# Setting for output figures
plt.close('all')
mpl.rc('axes', labelsize=16)
mpl.rc('xtick', labelsize=14)
mpl.rc('ytick', labelsize=14)

# FUNCTIONS
# Function for figures
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "TensileStrength_v1"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "figures_regression", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving figure: ", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

def save_pdf(fig_id, resolution=400,tight_layout=True,fig_extension="pdf"):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving pdf: ", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

# Upload raw data
# You need to upload excel file to this colab file to run it by yourself
read_data = pd.read_csv('database.csv', delimiter=",")
read_data = read_data.iloc[:, 2:] #Remove the first two columns (source and data-code)
data_comp = read_data.copy() #Copia para uso futuro
print(read_data.head(10))
print(read_data.info())

# Making a copy of data - Just in case
data_mod = read_data.copy() #KNN Imputer

# Checking for missing data points
print(data_mod.isnull().sum())

# Making a data imputation
# 3. Imputación KNN
imputer = KNNImputer(n_neighbors=100)
data_mod['fc_ad'] = imputer.fit_transform(data_mod[['ad', 'fc_ad']])[:, 1]
print(data_mod.isnull().sum())

# ==== Part 2: Initial Data exploration
# Output of Initial data statistics of KNN imputer dataset
TABLES_PATH = os.path.join(PROJECT_ROOT_DIR, "Tables_Output_Regression")
os.makedirs(TABLES_PATH, exist_ok=True)
file_table = path = os.path.join(TABLES_PATH, 'initial_DataStats.csv')
Data_statistics = data_mod.describe()
print(Data_statistics)
# Plots - histograms of original features
for xx in data_mod.columns:
    plt.figure(figsize=(6,4))
    plt.hist(data_mod[xx],bins=30)
    plt.ylabel("Number", fontsize=14)
    plt.xlabel(xx, fontsize=14)
    save_fig("histogram_plot_"+xx)

#---- Applying the ANOVA F-test
results = []
for column in data_mod.columns[:-2]:  # Excluye la última columna que es la variable dependiente
    model = ols(f'Nu ~ {column}', data=data_mod).fit()
    results.append({
        'Variable': column,
        'F-value': model.fvalue,
        'p-value': model.f_pvalue
    })

# Crea un DataFrame con los resultados
results_df = pd.DataFrame(results)

# Ordena los resultados por p-value
results_df = results_df.sort_values(by='p-value')

print(results_df)

# Getting initial correlation matrix - KNN Imputer
Init_corr = data_mod.corr()
print("--- Initial Correlation Matrix")
print(Init_corr)
file_table = path = os.path.join(TABLES_PATH, 'initial_correlation.csv')

# ------- Definition of strata for split of data - Based on Nu
print(data_mod['Nu'].describe())
# Defining range for strata
bins = [5,20,40,70, 150, 3000]
names = [1,2,3,4, 5]
data_mod["strata_Nu"] = pd.cut(data_mod['Nu'],bins,labels = names)
# Checking for missing data points
print(data_mod.isnull().sum())
plt.figure(figsize=(5,4.5))
plt.hist(data_mod["strata_Nu"])
data_mod["strata_Nu"].describe()

# Now data_mod includes categorical values for strata_Nu
data_mod

# Making some modifications to feature - Increasing correlation
# converting to log some features
var_names_to_log = [ 'fc' , 'Nu' ]
data_mod_log = data_mod.copy()
for feature in var_names_to_log:
    data_mod_log[feature] = np.log(data_mod_log[feature])
# Total List of features
names2 = ['d', 'd_hole', 'hef', 'ad', 'fc_ad', 'log_fc', 'bar', 'fu', 'log_Nu', 'FM',
           'strata_fc']
data_mod_log.columns = names2
# List of features with only numerical value
names_num = ['d', 'hef', 'ad', 'fc_ad', 'log_fc', 'bar', 'fu', 'log_Nu']

# Getting correlation matrix for new features
New_corr = data_mod_log[names_num].corr()
print("--- Initial Correlation Matrix")
print(Init_corr)
print("--- New Correlation Matrix")
print(New_corr)


# Visualization of correlation among final attributes
plt.figure(figsize=(10, 8))
sns.heatmap(data_mod_log[names_num].corr(), annot=True, fmt='.2g', center= 0,
    cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.6, square=True,
            annot_kws={"size": 18}, xticklabels=names_num, yticklabels=names_num)
save_fig("correlation_matrix_with_output")

# ================ Part 3: Preparing data for ML models
# Defining final inputs and output
Input_var = ['d', 'hef','ad', 'fc_ad', 'log_fc', 'bar', 'fu']
Target_var = ['log_Nu']
X_data = data_mod_log[Input_var]
Y_data = data_mod_log[Target_var]
X_data

# Split of dataset
# You can choose the variable for strata
# Note: Using a strattified random shuffle split of data - 8:2 ratio
# Note: Using strata based on fc
XX_train, XX_test, YY_train, YY_test = train_test_split(
    X_data, Y_data, test_size=0.2, random_state=42,
    stratify=data_mod['strata_Nu'])
YY_train

# === Definition of main scaler for training models
# Notes:
# - Scaler only affects X data in train set
# - Use the same scaler for new data
# - Standard scaler for features
# - Save parameters of scalers for the interface

scaler = StandardScaler()
X_train_slr = scaler.fit(XX_train)
print("--- Mean values of data ---")
print(X_train_slr.mean_)
print("--- Variance of data ---")
print(X_train_slr.var_)
print("--- STD (scale factor) for data ---")
print(X_train_slr.scale_)

# - Scaler only affects X data - Full data

X_data_slr = StandardScaler(with_mean=True, with_std = True).fit(X_data)
print("--- Mean values of data ---")
print(X_data_slr.mean_)
print("--- Variance of data ---")
print(X_data_slr.var_)
print("--- STD (scale factor) for data ---")
print(X_data_slr.scale_)

# Checking differences in scaler - test Data
X_test_slr = scaler.fit(XX_test)
print("--- Mean values of data ---")
print(X_test_slr.mean_)
print("--- Variance of data ---")
print(X_test_slr.var_)
print("--- STD (scale factor) for data ---")
print(X_test_slr.scale_)

# Applying the main scaler to both datasets
XX_train_sca = pd.DataFrame(X_train_slr.transform(XX_train), columns = Input_var)
XX_test_sca = pd.DataFrame(X_train_slr.transform(XX_test), columns = Input_var)
print(XX_train_sca.describe())

# ==== Part 4: Training ML models
# Functions for Performance metrics
# Mean Average Relative Difference (MARD)

#Indicators were modifided to transform from logNu to Nu
def r2_LOG(X, Y):
    pred = np.array(np.exp(Y))
    real = np.array(np.exp(X))
    dif = real - pred
    r2 = 1 - (np.sum(dif**2) / np.sum((real - np.mean(real))**2))
    return r2

def rmse_LOG(X, Y):
    pred = np.array(np.exp(Y))
    real = np.array(np.exp(X))
    dif = real - pred
    rmse = np.sqrt(np.mean(dif**2))
    return rmse


def mard_LOG(X, Y):
    pred = np.array(np.exp(Y))
    real = np.array(np.exp(X))
    n = len(Y) #finding total number of items in list
    ard=[]
    for i in range(n):
        difference=np.abs(pred[i]-real[i])
        div=np.abs(difference/real[i])
        ard.append(div)
    mard_=np.median(ard)
    return(mard_)
#D%
def D_percentage_LOG(X, Y, Z=25):
    pred = np.array(np.exp(Y))
    real = np.array(np.exp(X))
    n = len(Y) #finding total number of items in list
    contador=0
    for i in range(n):
        difference=np.abs(pred[i]-real[i])
        div=np.abs(difference/real[i])
        if div<=(Z/100):
            contador+=1
    D_percent=contador/n
    return(D_percent*100)

#
def display_scores(scores):
    mean_r2= scores["test_r2"].mean()
    standard_deviation_r2= scores["test_r2"].std()
    mean_rmse= scores["test_rmse"].mean()
    standard_deviation_rmse= scores["test_rmse"].std()
    mean_mard= scores["test_mard"].mean()
    standard_deviation_mard= scores["test_mard"].std()
    mean_D_percentage= scores["test_D%"].mean()
    standard_deviation_D_percentage= scores["test_D%"].std()
    return [round(mean_r2,5),round(standard_deviation_r2,5),
            round(mean_rmse,5),round(standard_deviation_rmse,5),
            round(mean_mard,5),round(standard_deviation_mard,5),
            round(mean_D_percentage,5),round(standard_deviation_D_percentage,5)]
#

# Performing the Cross-Validation of 3 models
# Note: the error in metrics is measured in terms of Nu
Validation_chart=[]
K_fold = 10 #Al alternar resulta 10, como la mejor opción
scoring = {'mard': make_scorer(mard_LOG),
           'D%': make_scorer(D_percentage_LOG),
           'r2': make_scorer(r2_LOG),
           'rmse': make_scorer(rmse_LOG)
           }
# Random Forest
RF_reg = RandomForestRegressor(random_state=42)
rf_cv = cross_validate(RF_reg, XX_train_sca, YY_train.to_numpy().ravel(), scoring=scoring, cv=K_fold, error_score='raise')
Validation_chart.append(display_scores(rf_cv))
# GBM
GBM_reg = GradientBoostingRegressor(random_state=42)
gbm_cv = cross_validate(GBM_reg, XX_train_sca, YY_train.to_numpy().ravel(), scoring=scoring, cv=K_fold, error_score='raise')
Validation_chart.append(display_scores(gbm_cv))
# XG Boost
xgb_reg = xgb.XGBRegressor(random_state=42)
xgb_cv = cross_validate(xgb_reg, XX_train_sca, YY_train.to_numpy().ravel(), scoring=scoring, cv=K_fold, error_score='raise')
Validation_chart.append(display_scores(xgb_cv))
Validation_chart


# ============ Part 5:Tuning of the candidate ML model - XGBoost
# Checking for best hyperparameters with GridSearch
param_grid = {'learning_rate': [0.3],
              'max_depth':[2],
              'n_estimators': [200],
              'min_child_weight' : [2]}
print(xgb_reg.get_params())
grid_search = GridSearchCV(xgb_reg, param_grid, cv=K_fold,
                           scoring="r2",return_train_score=True
                           , verbose=1)
grid_search.fit(XX_train_sca, YY_train)
print(grid_search.best_params_)
print(grid_search.best_estimator_)

#============ Part 7: Validation of model with the testset
final_model = grid_search.best_estimator_
# Predictions in the training set
YY_pred_final = final_model.predict(XX_train_sca)
YY_train_final = YY_train['log_Nu']
#
# NOTE: Prediction errors are in terms of Nu
final_rmse = rmse_LOG(YY_train_final, YY_pred_final)
final_R2 = r2_LOG(YY_train_final, YY_pred_final)
final_mard=mard_LOG(YY_train_final, YY_pred_final)
final_D=D_percentage_LOG(YY_train_final, YY_pred_final,25)
print('TRAINING SET')
print("Root_mean_squared_error: ", final_rmse)
print("R2: ", final_R2)
print("MARD: ", final_mard)
print("D%: ", final_D)
# Predictions in the testing set
YY_predtest_final = final_model.predict(XX_test_sca)
YY_test_final = YY_test['log_Nu']
final_test_rmse = rmse_LOG(YY_test_final, YY_predtest_final)
final_test_R2 = r2_LOG(YY_test_final, YY_predtest_final)
final_test_mard=mard_LOG(YY_test_final, YY_predtest_final)
final_test_D=D_percentage_LOG(YY_test_final, YY_predtest_final,25)
print('-----------------------')
print('TESTING SET')
print("Root_mean_squared_error: ", final_test_rmse)
print("R2: ", final_test_R2)
print("MARD: ", final_test_mard)
print("D%: ", final_test_D)
print('-----------------------')

# Plot of final performance
cLegend = "Training set metrics:" + "\n" \
        + "RMSE =  " + str(round(final_rmse,1)) + "\n" \
        + "R²      = " + str(round(final_R2,2)) + "\n" \
        + "MARD = " + str(round(final_mard,2)) + "\n" \
        + "D10% = " + str(round(final_D,2)) + '%'+  "\n" \
        + "\n" \
        + "Testing set metrics:" + "\n" \
        + "RMSE =  " + str(round(final_test_rmse,1)) + "\n" \
        + "R²      = " + str(round(final_test_R2,2)) + "\n" \
        + "MARD = " + str(round(final_test_mard,2)) + "\n" \
        + "D10% = " + str(round(final_test_D,2)) +'%'
Val_min = min(YY_train_final.min(),YY_pred_final.min(), YY_predtest_final.min(),
              YY_test_final.min())
Val_max = max(YY_train_final.max(),YY_pred_final.max(), YY_predtest_final.max(),
              YY_test_final.max())
plt.figure(figsize=(9,7))
plt.scatter(YY_pred_final, YY_train_final, label='Training set',s=20) # train
plt.scatter(YY_predtest_final, YY_test_final, marker="s",s=20,label='Testing set') # test
plt.plot(np.linspace(Val_min, Val_max, num=10),np.linspace(Val_min, Val_max, num=10), color='red')
plt.xlabel("Predicción de la resistencia a la tracción - Ln Nu (kN)")
plt.ylabel("Valor real de la resistencia a la tracción - Ln Nu (kN)")
plt.xticks()
plt.yticks()
plt.legend()
plt.grid(False)
save_fig("Regression_FinalXGB_plot")
plt.show()

YY_pred_final_normal = np.exp(YY_pred_final)
YY_train_final_normal = np.exp(YY_train_final)

YY_predtest_final_normal = np.exp(YY_predtest_final)
YY_test_final_normal = np.exp(YY_test_final)

Val_min = min(YY_train_final_normal.min(),YY_pred_final_normal.min(), YY_predtest_final_normal.min(),
              YY_test_final_normal.min())
Val_max = max(YY_train_final_normal.max(),YY_pred_final_normal.max(), YY_predtest_final_normal.max(),
              YY_test_final_normal.max())
plt.figure(figsize=(9,7))
plt.scatter(YY_pred_final_normal, YY_train_final_normal, label='Training set',s=20) # train
plt.scatter(YY_predtest_final_normal, YY_test_final_normal, marker="s",s=20,label='Testing set') # test
plt.plot(np.linspace(Val_min, Val_max, num=10),np.linspace(Val_min, Val_max, num=10), color='red')
plt.xlabel("Predicción de la resistencia a la tracción (kN)")
plt.ylabel("Valor real de la resistencia a la tracción (kN)")
plt.xticks()
plt.yticks()
plt.legend()
plt.grid(False)
save_fig("Regression_FinalXGB_plot")


def app_adhesive(d_, hef_, ad_, fc_ad_, fc_, bar_, fu_):
  loga_fc = np.log(fc_)

  data = {
      'd' : d_,
      'hef' : hef_,
      'ad' : ad_,
      'fc_ad' : fc_ad_,
      'log_fc' : loga_fc,
      'bar' : bar_,
      'fu' : fu_
  }
  print(f'data: {data}')
  In_var = ['d', 'hef','ad', 'fc_ad', 'log_fc', 'bar', 'fu']

  datos_x = pd.DataFrame(data, index = [0])
  print(f'datos_x: {datos_x}')

  sca_datos_x = pd.DataFrame(X_data_slr.transform(datos_x),columns = In_var)
  print(f'sca_datos_x: {sca_datos_x}')

  Nu_pred = final_model.predict(sca_datos_x)
  print(Nu_pred)
  Nu_pred_ = np.exp(Nu_pred)

  return Nu_pred_
